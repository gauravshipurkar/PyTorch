{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Preprocessing&Classification_Using-PyTorch.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Complete Pipeline**"
      ],
      "metadata": {
        "id": "Db8WbWtCewN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Urban Sound Dataset**"
      ],
      "metadata": {
        "id": "YXzhMmyA054O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "4c8Li-YP0_UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoAVwnYa8Pkx",
        "outputId": "7ede3110-e068-4ab4-904d-8760969cd3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar -xzvf \"/content/drive/MyDrive/Classification/Audio_Classification/UrbanSound8K.tar.gz\" -C \"/content/drive/MyDrive/Classification/Audio_Classification/\"  "
      ],
      "metadata": {
        "id": "2kCm5hDUMj1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(Dataset):\n",
        "\n",
        "  def __init__(self, annotations_file, audio_dir, transformation, target_sample_rate, num_samples):\n",
        "\n",
        "    self.annotations = pd.read_csv(annotations_file)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.transformation = transformation\n",
        "    self.target_sample_rate = target_sample_rate\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "  def __len__(self):\n",
        "    \n",
        "    return len(self.annotations)\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    audio_sample_path = self._get_audio_sample_path(index)\n",
        "    label = self._get_audio_sample_label(index)\n",
        "    signal, sr  = torchaudio.load(audio_sample_path)\n",
        "    signal = self._resample_if_necessary(signal,sr)\n",
        "    signal = self._mix_down_if_necessary(signal)\n",
        "    signal = self._cut_if_necessary(signal)\n",
        "    signal = self._right_pad_if_necessary(signal)\n",
        "    signal = self.transformation(signal)\n",
        "\n",
        "    return signal, label\n",
        "\n",
        "  def _cut_if_necessary(self,signal):\n",
        "\n",
        "    if signal.shape[1] > self.num_samples:\n",
        "      signal = signal[:, :self.num_samples]\n",
        "\n",
        "    return signal\n",
        "  \n",
        "  def _right_pad_if_necessary(self,signal):\n",
        "\n",
        "    if signal.shape[1]<self.num_samples:\n",
        "      num_missing_samples = self.num_samples - signal.shape[1]\n",
        "      last_dim_padding = (0,num_missing_samples)\n",
        "      signal = torch.nn.functional.pad(signal,last_dim_padding)\n",
        "    \n",
        "    return signal\n",
        "\n",
        "  def _resample_if_necessary(self,signal,sr):\n",
        "\n",
        "    if sr != self.target_sample_rate:\n",
        "      resampler = torchaudio.transforms.Resample(sr,self.target_sample_rate)\n",
        "      signal = resampler(signal)\n",
        "    return signal\n",
        "  \n",
        "  def _mix_down_if_necessary(self, signal):\n",
        "\n",
        "    if signal.shape[0] > 1:\n",
        "        signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "\n",
        "    return signal\n",
        "\n",
        "\n",
        "  def _get_audio_sample_path(self,index):\n",
        "    fold = f\"fold{self.annotations.iloc[index, 5]}\"\n",
        "    path = Path(self.audio_dir + fold + '/' + self.annotations.iloc[index, 0])\n",
        "    return path\n",
        "\n",
        "  def _get_audio_sample_label(self, index):\n",
        "    return self.annotations.iloc[index, 6]"
      ],
      "metadata": {
        "id": "B3n4uCcF1Lro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "Sample_Rate = 22050\n",
        "num_samples = 22050\n"
      ],
      "metadata": {
        "id": "VHi11i4xK49q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "85gCKUDTsM2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "class CNNNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d( in_channels = 1, out_channels = 32, kernel_size=3, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d( in_channels = 32, out_channels = 64, kernel_size=3, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "        \n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d( in_channels = 64, out_channels = 128, kernel_size=3, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "        \n",
        "    )\n",
        "    self.conv4 = nn.Sequential(\n",
        "        nn.Conv2d( in_channels = 128, out_channels = 256, kernel_size=3, stride=1, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "        \n",
        "    )\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear( 256*5*4, 10)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input_data):\n",
        "\n",
        "    x = self.conv1(input_data)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear(x)\n",
        "    predictions = self.softmax(logits)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "RxtKvTAvqJbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model-Training**"
      ],
      "metadata": {
        "id": "ZjbPUgfWsSxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
        "\n",
        "  for inputs, targets in tqdm(data_loader):\n",
        "    inputs,targets = inputs.to(device), targets.to(device)\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_fn(predictions,targets)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "  \n",
        "  print(f\"Loss:{loss.item()}\")\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "\n",
        "  for i in range(epochs):\n",
        "    print(f\"Epoch:{i+1}\")\n",
        "    train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
        "\n",
        "  print(\"Training Complete\")\n",
        "\n",
        "def create_data_loader(train_data, batch_size):\n",
        "\n",
        "  train_dataloader = DataLoader(train_data, batch_size = batch_size)\n",
        "  return train_dataloader"
      ],
      "metadata": {
        "id": "rzI7VucNKuJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "  else:\n",
        "    device = 'cpu'\n",
        "\n",
        "  annotations_file = '/content/drive/MyDrive/Classification/Audio_Classification/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "  audio_dir = '/content/drive/MyDrive/Classification/Audio_Classification/UrbanSound8K/audio/'\n",
        "\n",
        "  mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=Sample_Rate, n_fft=1024, hop_length=512, n_mels=64)\n",
        "  usd = UrbanSoundDataset( annotations_file, audio_dir, mel_spectrogram, Sample_Rate, num_samples)\n",
        "  train_data_loader = DataLoader( usd, batch_size = BATCH_SIZE)\n",
        "  signal, label = usd[0]\n",
        "  feed_forward_net = CNNNetwork().to(device)\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimiser = torch.optim.Adam(feed_forward_net.parameters(),lr = 0.0001)\n",
        "\n",
        "  train( feed_forward_net, train_data_loader, loss_fn, optimiser, device, EPOCHS)\n",
        "  torch.save(feed_forward_net.state_dict(), \"feedforwardnet.pth\")\n",
        "  print(\"Model trained and stored at feedforwardnet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgaRvSjZLoYO",
        "outputId": "f8669c7f-1629-429c-cbc8-3ec8a352a096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.2449381351470947\n",
            "Epoch:2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:35<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.2027533054351807\n",
            "Epoch:3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.1946494579315186\n",
            "Epoch:4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.1176228523254395\n",
            "Epoch:5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.1613874435424805\n",
            "Epoch:6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.061757802963257\n",
            "Epoch:7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:27<00:00,  2.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.133641242980957\n",
            "Epoch:8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9920647144317627\n",
            "Epoch:9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9796364307403564\n",
            "Epoch:10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9715896844863892\n",
            "Epoch:11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9457685947418213\n",
            "Epoch:12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.930105209350586\n",
            "Epoch:13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9140983819961548\n",
            "Epoch:14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9059288501739502\n",
            "Epoch:15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:27<00:00,  2.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.939225196838379\n",
            "Epoch:16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.0358150005340576\n",
            "Epoch:17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9305543899536133\n",
            "Epoch:18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:2.096281051635742\n",
            "Epoch:19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.929892897605896\n",
            "Epoch:20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9084863662719727\n",
            "Epoch:21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9299439191818237\n",
            "Epoch:22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9227354526519775\n",
            "Epoch:23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9392348527908325\n",
            "Epoch:24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.916399359703064\n",
            "Epoch:25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9377614259719849\n",
            "Epoch:26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.8215843439102173\n",
            "Epoch:27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9191361665725708\n",
            "Epoch:28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:28<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.908983826637268\n",
            "Epoch:29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9204531908035278\n",
            "Epoch:30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [02:29<00:00,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:1.9179407358169556\n",
            "Training Complete\n",
            "Model trained and stored at feedforwardnet.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing**\n",
        "\n"
      ],
      "metadata": {
        "id": "X3OuanBwscfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class_mapping = [\n",
        "    \"air_conditioner\",\n",
        "    \"car_horn\",\n",
        "    \"children_playing\",\n",
        "    \"dog_bark\",\n",
        "    \"drilling\",\n",
        "    \"engine_idling\",\n",
        "    \"gun_shot\",\n",
        "    \"jackhammer\",\n",
        "    \"siren\",\n",
        "    \"street_music\"\n",
        "]\n",
        "\n",
        "\n",
        "def predict(model, input, target, class_mapping):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input)\n",
        "        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n",
        "        predicted_index = predictions[0].argmax(0)\n",
        "        predicted = class_mapping[predicted_index]\n",
        "        expected = class_mapping[target]\n",
        "    return predicted, expected\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load back the model\n",
        "    cnn = CNNNetwork()\n",
        "    state_dict = torch.load(\"/content/feedforwardnet.pth\")\n",
        "    cnn.load_state_dict(state_dict)\n",
        "\n",
        "    # load urban sound dataset dataset\n",
        "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate = Sample_Rate,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=64\n",
        "    )\n",
        "\n",
        "    usd = UrbanSoundDataset(annotations_file, audio_dir, mel_spectrogram, Sample_Rate, num_samples)\n",
        "\n",
        "\n",
        "    # get a sample from the urban sound dataset for inference\n",
        "    input, target = usd[0][0], usd[0][1] # [batch size, num_channels, fr, time]\n",
        "    input.unsqueeze_(0)\n",
        "\n",
        "    # make an inference\n",
        "    predicted, expected = predict(cnn, input, target,class_mapping)\n",
        "    print(f\"Predicted: '{predicted}', expected: '{expected}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_XpufmYosXU",
        "outputId": "d6262176-8598-4a27-eb14-5dcf823664ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 'dog_bark', expected: 'dog_bark'\n"
          ]
        }
      ]
    }
  ]
}